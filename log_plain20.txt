Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 1.923 (1.923)	Data 0.135 (0.135)	Loss 2.3244 (2.3244)	Prec@1 12.000 (12.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.032 (0.055)	Data 0.019 (0.022)	Loss 1.7125 (1.9540)	Prec@1 37.000 (25.188)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.033 (0.044)	Data 0.020 (0.022)	Loss 1.6244 (1.8344)	Prec@1 39.500 (29.883)
 * Training Prec@1 31.672
Test: [0/50]	Time 0.127 (0.127)	Loss 1.6389 (1.6389)	Prec@1 42.000 (42.000)
 * Testing Prec@1 38.510
Epoch: [1/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.124 (0.124)	Loss 1.5533 (1.5533)	Prec@1 38.000 (38.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.021 (0.023)	Loss 1.4935 (1.5158)	Prec@1 48.000 (43.455)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.019 (0.022)	Loss 1.2007 (1.4373)	Prec@1 56.500 (46.933)
 * Training Prec@1 48.306
Test: [0/50]	Time 0.148 (0.148)	Loss 1.2864 (1.2864)	Prec@1 49.500 (49.500)
 * Testing Prec@1 52.220
Epoch: [2/80][0/250]	LR: 0.1	Time 0.138 (0.138)	Data 0.117 (0.117)	Loss 1.2251 (1.2251)	Prec@1 57.500 (57.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.020 (0.021)	Loss 1.0109 (1.1931)	Prec@1 63.500 (56.743)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.019 (0.022)	Loss 0.9801 (1.1464)	Prec@1 68.000 (58.595)
 * Training Prec@1 59.412
Test: [0/50]	Time 0.119 (0.119)	Loss 1.0762 (1.0762)	Prec@1 61.500 (61.500)
 * Testing Prec@1 59.260
Epoch: [3/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.112 (0.112)	Loss 1.2361 (1.2361)	Prec@1 56.500 (56.500)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.020 (0.023)	Loss 0.8196 (0.9767)	Prec@1 69.000 (65.203)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.031 (0.035)	Data 0.019 (0.022)	Loss 0.9451 (0.9499)	Prec@1 69.000 (66.206)
 * Training Prec@1 66.488
Test: [0/50]	Time 0.100 (0.100)	Loss 0.8250 (0.8250)	Prec@1 73.500 (73.500)
 * Testing Prec@1 67.710
Epoch: [4/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.137 (0.137)	Loss 0.8825 (0.8825)	Prec@1 70.500 (70.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.019 (0.023)	Loss 0.9043 (0.8414)	Prec@1 67.000 (70.030)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.7099 (0.8286)	Prec@1 77.500 (70.687)
 * Training Prec@1 70.946
Test: [0/50]	Time 0.100 (0.100)	Loss 0.9201 (0.9201)	Prec@1 70.000 (70.000)
 * Testing Prec@1 66.810
Epoch: [5/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.141 (0.141)	Loss 0.7538 (0.7538)	Prec@1 72.500 (72.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.043 (0.039)	Data 0.025 (0.023)	Loss 0.7049 (0.7677)	Prec@1 75.000 (73.054)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.021 (0.022)	Loss 0.6976 (0.7504)	Prec@1 75.500 (73.726)
 * Training Prec@1 73.928
Test: [0/50]	Time 0.107 (0.107)	Loss 0.8076 (0.8076)	Prec@1 73.500 (73.500)
 * Testing Prec@1 70.720
Epoch: [6/80][0/250]	LR: 0.1	Time 0.128 (0.128)	Data 0.108 (0.108)	Loss 0.5982 (0.5982)	Prec@1 80.000 (80.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.021 (0.023)	Loss 0.7306 (0.6933)	Prec@1 74.000 (75.777)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.023 (0.022)	Loss 0.5083 (0.6873)	Prec@1 81.500 (76.124)
 * Training Prec@1 76.346
Test: [0/50]	Time 0.106 (0.106)	Loss 0.7497 (0.7497)	Prec@1 74.000 (74.000)
 * Testing Prec@1 72.960
Epoch: [7/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.142 (0.142)	Loss 0.7227 (0.7227)	Prec@1 75.500 (75.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.021 (0.020)	Loss 0.6802 (0.6452)	Prec@1 76.500 (77.668)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.017 (0.019)	Loss 0.6606 (0.6439)	Prec@1 78.500 (77.724)
 * Training Prec@1 77.836
Test: [0/50]	Time 0.103 (0.103)	Loss 0.7453 (0.7453)	Prec@1 77.000 (77.000)
 * Testing Prec@1 70.520
Epoch: [8/80][0/250]	LR: 0.1	Time 0.106 (0.106)	Data 0.085 (0.085)	Loss 0.4785 (0.4785)	Prec@1 86.500 (86.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.031 (0.035)	Data 0.016 (0.020)	Loss 0.6514 (0.6110)	Prec@1 75.500 (78.629)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.018 (0.020)	Loss 0.5670 (0.6149)	Prec@1 80.000 (78.580)
 * Training Prec@1 78.698
Test: [0/50]	Time 0.084 (0.084)	Loss 0.6789 (0.6789)	Prec@1 75.000 (75.000)
 * Testing Prec@1 74.600
Epoch: [9/80][0/250]	LR: 0.1	Time 0.139 (0.139)	Data 0.116 (0.116)	Loss 0.4926 (0.4926)	Prec@1 84.500 (84.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.031 (0.035)	Data 0.016 (0.020)	Loss 0.5167 (0.5634)	Prec@1 80.500 (80.411)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.018 (0.020)	Loss 0.4761 (0.5653)	Prec@1 81.000 (80.336)
 * Training Prec@1 80.182
Test: [0/50]	Time 0.105 (0.105)	Loss 0.7111 (0.7111)	Prec@1 77.500 (77.500)
 * Testing Prec@1 75.270
Epoch: [10/80][0/250]	LR: 0.1	Time 0.112 (0.112)	Data 0.094 (0.094)	Loss 0.4241 (0.4241)	Prec@1 86.000 (86.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.031 (0.037)	Data 0.018 (0.022)	Loss 0.4885 (0.5520)	Prec@1 81.500 (81.015)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.043 (0.037)	Data 0.025 (0.022)	Loss 0.5291 (0.5573)	Prec@1 84.500 (80.900)
 * Training Prec@1 81.128
Test: [0/50]	Time 0.104 (0.104)	Loss 0.8496 (0.8496)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.480
Epoch: [11/80][0/250]	LR: 0.1	Time 0.197 (0.197)	Data 0.172 (0.172)	Loss 0.4329 (0.4329)	Prec@1 86.000 (86.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.020 (0.021)	Loss 0.5485 (0.5269)	Prec@1 83.000 (81.837)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.020 (0.020)	Loss 0.6395 (0.5260)	Prec@1 78.500 (81.853)
 * Training Prec@1 81.748
Test: [0/50]	Time 0.079 (0.079)	Loss 0.5535 (0.5535)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.160
Epoch: [12/80][0/250]	LR: 0.1	Time 0.109 (0.109)	Data 0.090 (0.090)	Loss 0.5041 (0.5041)	Prec@1 84.000 (84.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.032 (0.037)	Data 0.019 (0.022)	Loss 0.4574 (0.5162)	Prec@1 82.500 (82.153)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.021 (0.022)	Loss 0.4470 (0.5143)	Prec@1 83.000 (82.189)
 * Training Prec@1 82.362
Test: [0/50]	Time 0.103 (0.103)	Loss 0.8673 (0.8673)	Prec@1 72.500 (72.500)
 * Testing Prec@1 73.950
Epoch: [13/80][0/250]	LR: 0.1	Time 0.114 (0.114)	Data 0.093 (0.093)	Loss 0.4653 (0.4653)	Prec@1 83.500 (83.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.018 (0.020)	Loss 0.4571 (0.4887)	Prec@1 84.500 (82.703)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.017 (0.019)	Loss 0.4506 (0.4866)	Prec@1 83.500 (82.940)
 * Training Prec@1 82.974
Test: [0/50]	Time 0.102 (0.102)	Loss 0.6778 (0.6778)	Prec@1 80.000 (80.000)
 * Testing Prec@1 77.220
Epoch: [14/80][0/250]	LR: 0.1	Time 0.173 (0.173)	Data 0.148 (0.148)	Loss 0.5088 (0.5088)	Prec@1 82.000 (82.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.4773 (0.4726)	Prec@1 83.500 (83.703)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.018 (0.021)	Loss 0.4913 (0.4803)	Prec@1 83.000 (83.460)
 * Training Prec@1 83.458
Test: [0/50]	Time 0.103 (0.103)	Loss 0.6777 (0.6777)	Prec@1 75.000 (75.000)
 * Testing Prec@1 76.650
Epoch: [15/80][0/250]	LR: 0.1	Time 0.153 (0.153)	Data 0.131 (0.131)	Loss 0.4574 (0.4574)	Prec@1 83.000 (83.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.019 (0.022)	Loss 0.4983 (0.4708)	Prec@1 81.500 (83.678)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.042 (0.037)	Data 0.026 (0.022)	Loss 0.3849 (0.4690)	Prec@1 87.500 (83.679)
 * Training Prec@1 83.772
Test: [0/50]	Time 0.087 (0.087)	Loss 0.5765 (0.5765)	Prec@1 82.500 (82.500)
 * Testing Prec@1 78.830
Epoch: [16/80][0/250]	LR: 0.1	Time 0.146 (0.146)	Data 0.121 (0.121)	Loss 0.4145 (0.4145)	Prec@1 84.500 (84.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.019 (0.021)	Loss 0.5243 (0.4387)	Prec@1 82.500 (84.728)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.017 (0.020)	Loss 0.4420 (0.4480)	Prec@1 86.500 (84.418)
 * Training Prec@1 84.336
Test: [0/50]	Time 0.149 (0.149)	Loss 0.7538 (0.7538)	Prec@1 75.000 (75.000)
 * Testing Prec@1 74.530
Epoch: [17/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.099 (0.099)	Loss 0.3776 (0.3776)	Prec@1 88.000 (88.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.019 (0.020)	Loss 0.5096 (0.4339)	Prec@1 81.500 (85.163)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.037 (0.033)	Data 0.022 (0.019)	Loss 0.3732 (0.4375)	Prec@1 87.500 (84.891)
 * Training Prec@1 84.820
Test: [0/50]	Time 0.069 (0.069)	Loss 0.5780 (0.5780)	Prec@1 81.500 (81.500)
 * Testing Prec@1 79.520
Epoch: [18/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.135 (0.135)	Loss 0.3640 (0.3640)	Prec@1 87.500 (87.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.043 (0.037)	Data 0.026 (0.022)	Loss 0.3733 (0.4204)	Prec@1 88.000 (85.139)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.018 (0.020)	Loss 0.4736 (0.4246)	Prec@1 82.500 (85.112)
 * Training Prec@1 84.932
Test: [0/50]	Time 0.114 (0.114)	Loss 0.6963 (0.6963)	Prec@1 77.500 (77.500)
 * Testing Prec@1 76.570
Epoch: [19/80][0/250]	LR: 0.1	Time 0.175 (0.175)	Data 0.149 (0.149)	Loss 0.3721 (0.3721)	Prec@1 86.500 (86.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.021 (0.021)	Loss 0.4270 (0.4083)	Prec@1 85.500 (85.802)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.021 (0.022)	Loss 0.3285 (0.4225)	Prec@1 89.000 (85.371)
 * Training Prec@1 85.452
Test: [0/50]	Time 0.102 (0.102)	Loss 0.8143 (0.8143)	Prec@1 77.500 (77.500)
 * Testing Prec@1 74.850
Epoch: [20/80][0/250]	LR: 0.1	Time 0.113 (0.113)	Data 0.092 (0.092)	Loss 0.4357 (0.4357)	Prec@1 82.500 (82.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.039 (0.035)	Data 0.023 (0.022)	Loss 0.3600 (0.4090)	Prec@1 87.500 (85.980)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.035 (0.034)	Data 0.022 (0.021)	Loss 0.5568 (0.4112)	Prec@1 81.500 (85.900)
 * Training Prec@1 85.776
Test: [0/50]	Time 0.074 (0.074)	Loss 0.5751 (0.5751)	Prec@1 82.500 (82.500)
 * Testing Prec@1 80.820
Epoch: [21/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.095 (0.095)	Loss 0.3761 (0.3761)	Prec@1 88.000 (88.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.019 (0.020)	Loss 0.3187 (0.3981)	Prec@1 89.000 (86.332)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.020 (0.021)	Loss 0.4636 (0.4043)	Prec@1 83.000 (86.012)
 * Training Prec@1 86.088
Test: [0/50]	Time 0.109 (0.109)	Loss 0.6266 (0.6266)	Prec@1 81.000 (81.000)
 * Testing Prec@1 80.600
Epoch: [22/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.135 (0.135)	Loss 0.3658 (0.3658)	Prec@1 86.000 (86.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.031 (0.035)	Data 0.018 (0.020)	Loss 0.3982 (0.3892)	Prec@1 87.000 (86.807)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.034 (0.034)	Data 0.020 (0.020)	Loss 0.5054 (0.3913)	Prec@1 83.500 (86.542)
 * Training Prec@1 86.574
Test: [0/50]	Time 0.107 (0.107)	Loss 0.5001 (0.5001)	Prec@1 85.000 (85.000)
 * Testing Prec@1 81.030
Epoch: [23/80][0/250]	LR: 0.1	Time 0.138 (0.138)	Data 0.114 (0.114)	Loss 0.4475 (0.4475)	Prec@1 84.000 (84.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.020 (0.022)	Loss 0.3776 (0.3916)	Prec@1 85.500 (86.490)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.018 (0.020)	Loss 0.3624 (0.3941)	Prec@1 86.500 (86.328)
 * Training Prec@1 86.360
Test: [0/50]	Time 0.108 (0.108)	Loss 0.7344 (0.7344)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.410
Epoch: [24/80][0/250]	LR: 0.1	Time 0.101 (0.101)	Data 0.080 (0.080)	Loss 0.4864 (0.4864)	Prec@1 83.000 (83.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.018 (0.020)	Loss 0.3467 (0.3863)	Prec@1 88.000 (86.520)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.020 (0.020)	Loss 0.3626 (0.3911)	Prec@1 89.500 (86.356)
 * Training Prec@1 86.366
Test: [0/50]	Time 0.076 (0.076)	Loss 0.8481 (0.8481)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.610
Epoch: [25/80][0/250]	LR: 0.1	Time 0.140 (0.140)	Data 0.117 (0.117)	Loss 0.3867 (0.3867)	Prec@1 85.500 (85.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.033 (0.039)	Data 0.018 (0.023)	Loss 0.3754 (0.3623)	Prec@1 88.000 (87.634)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.039 (0.037)	Data 0.023 (0.022)	Loss 0.4733 (0.3767)	Prec@1 82.000 (87.005)
 * Training Prec@1 86.910
Test: [0/50]	Time 0.087 (0.087)	Loss 0.4675 (0.4675)	Prec@1 82.500 (82.500)
 * Testing Prec@1 82.890
Epoch: [26/80][0/250]	LR: 0.1	Time 0.161 (0.161)	Data 0.140 (0.140)	Loss 0.3207 (0.3207)	Prec@1 88.500 (88.500)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.019 (0.022)	Loss 0.3896 (0.3657)	Prec@1 86.000 (87.228)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.018 (0.021)	Loss 0.2844 (0.3685)	Prec@1 90.000 (87.164)
 * Training Prec@1 86.956
Test: [0/50]	Time 0.072 (0.072)	Loss 0.7337 (0.7337)	Prec@1 77.500 (77.500)
 * Testing Prec@1 79.540
Epoch: [27/80][0/250]	LR: 0.1	Time 0.119 (0.119)	Data 0.095 (0.095)	Loss 0.3066 (0.3066)	Prec@1 88.000 (88.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.046 (0.035)	Data 0.029 (0.020)	Loss 0.3801 (0.3492)	Prec@1 85.500 (87.465)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.030 (0.035)	Data 0.013 (0.020)	Loss 0.3173 (0.3597)	Prec@1 90.500 (87.348)
 * Training Prec@1 87.244
Test: [0/50]	Time 0.109 (0.109)	Loss 0.6157 (0.6157)	Prec@1 81.500 (81.500)
 * Testing Prec@1 81.390
Epoch: [28/80][0/250]	LR: 0.1	Time 0.219 (0.219)	Data 0.195 (0.195)	Loss 0.3301 (0.3301)	Prec@1 91.000 (91.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.019 (0.022)	Loss 0.2872 (0.3515)	Prec@1 90.500 (87.832)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.033 (0.035)	Data 0.019 (0.020)	Loss 0.3123 (0.3589)	Prec@1 90.500 (87.609)
 * Training Prec@1 87.532
Test: [0/50]	Time 0.102 (0.102)	Loss 0.5480 (0.5480)	Prec@1 82.000 (82.000)
 * Testing Prec@1 81.540
Epoch: [29/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.160 (0.160)	Loss 0.3713 (0.3713)	Prec@1 86.000 (86.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.019 (0.023)	Loss 0.3563 (0.3565)	Prec@1 85.000 (87.658)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.032 (0.036)	Data 0.019 (0.021)	Loss 0.4291 (0.3593)	Prec@1 87.000 (87.570)
 * Training Prec@1 87.536
Test: [0/50]	Time 0.102 (0.102)	Loss 0.7939 (0.7939)	Prec@1 75.500 (75.500)
 * Testing Prec@1 76.740
Epoch: [30/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.093 (0.093)	Loss 0.3240 (0.3240)	Prec@1 86.500 (86.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.020 (0.021)	Loss 0.3134 (0.3561)	Prec@1 87.000 (87.564)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.034 (0.035)	Data 0.020 (0.020)	Loss 0.2793 (0.3542)	Prec@1 90.500 (87.570)
 * Training Prec@1 87.656
Test: [0/50]	Time 0.098 (0.098)	Loss 0.6045 (0.6045)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.030
Epoch: [31/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.128 (0.128)	Loss 0.3437 (0.3437)	Prec@1 87.000 (87.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.033 (0.039)	Data 0.022 (0.026)	Loss 0.4278 (0.3375)	Prec@1 85.500 (88.342)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.022 (0.025)	Loss 0.3888 (0.3431)	Prec@1 87.500 (88.241)
 * Training Prec@1 88.080
Test: [0/50]	Time 0.083 (0.083)	Loss 0.6288 (0.6288)	Prec@1 79.000 (79.000)
 * Testing Prec@1 79.850
Epoch: [32/80][0/250]	LR: 0.1	Time 0.148 (0.148)	Data 0.127 (0.127)	Loss 0.4243 (0.4243)	Prec@1 84.500 (84.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.039 (0.038)	Data 0.026 (0.024)	Loss 0.3334 (0.3497)	Prec@1 91.000 (87.718)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.024 (0.024)	Loss 0.4022 (0.3410)	Prec@1 87.500 (88.189)
 * Training Prec@1 88.168
Test: [0/50]	Time 0.081 (0.081)	Loss 0.6594 (0.6594)	Prec@1 77.000 (77.000)
 * Testing Prec@1 81.320
Epoch: [33/80][0/250]	LR: 0.1	Time 0.114 (0.114)	Data 0.099 (0.099)	Loss 0.2842 (0.2842)	Prec@1 90.500 (90.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.020 (0.025)	Loss 0.3841 (0.3251)	Prec@1 87.500 (88.827)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.022 (0.024)	Loss 0.2913 (0.3418)	Prec@1 89.500 (88.129)
 * Training Prec@1 88.060
Test: [0/50]	Time 0.106 (0.106)	Loss 0.5449 (0.5449)	Prec@1 81.500 (81.500)
 * Testing Prec@1 81.760
Epoch: [34/80][0/250]	LR: 0.1	Time 0.148 (0.148)	Data 0.126 (0.126)	Loss 0.3027 (0.3027)	Prec@1 88.000 (88.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.039 (0.037)	Data 0.026 (0.023)	Loss 0.3956 (0.3284)	Prec@1 86.000 (88.584)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.038 (0.037)	Data 0.025 (0.023)	Loss 0.3956 (0.3379)	Prec@1 88.000 (88.264)
 * Training Prec@1 88.170
Test: [0/50]	Time 0.127 (0.127)	Loss 0.5044 (0.5044)	Prec@1 81.000 (81.000)
 * Testing Prec@1 85.240
Epoch: [35/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.113 (0.113)	Loss 0.2692 (0.2692)	Prec@1 89.500 (89.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.020 (0.023)	Loss 0.2610 (0.3319)	Prec@1 89.500 (88.683)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.017 (0.022)	Loss 0.2852 (0.3302)	Prec@1 89.500 (88.679)
 * Training Prec@1 88.528
Test: [0/50]	Time 0.104 (0.104)	Loss 0.4462 (0.4462)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.760
Epoch: [36/80][0/250]	LR: 0.1	Time 0.173 (0.173)	Data 0.151 (0.151)	Loss 0.3171 (0.3171)	Prec@1 89.500 (89.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.034 (0.040)	Data 0.022 (0.026)	Loss 0.4723 (0.3142)	Prec@1 81.500 (88.960)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.023 (0.024)	Loss 0.3871 (0.3214)	Prec@1 85.500 (88.721)
 * Training Prec@1 88.702
Test: [0/50]	Time 0.080 (0.080)	Loss 0.4320 (0.4320)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.640
Epoch: [37/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.124 (0.124)	Loss 0.2320 (0.2320)	Prec@1 91.500 (91.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.023 (0.024)	Loss 0.2925 (0.3229)	Prec@1 89.500 (88.817)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.024 (0.024)	Loss 0.2920 (0.3191)	Prec@1 89.000 (88.910)
 * Training Prec@1 88.724
Test: [0/50]	Time 0.125 (0.125)	Loss 0.4658 (0.4658)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.920
Epoch: [38/80][0/250]	LR: 0.1	Time 0.102 (0.102)	Data 0.081 (0.081)	Loss 0.2540 (0.2540)	Prec@1 90.500 (90.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.019 (0.022)	Loss 0.2792 (0.3187)	Prec@1 91.000 (88.728)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.032 (0.035)	Data 0.019 (0.021)	Loss 0.3454 (0.3170)	Prec@1 89.000 (88.811)
 * Training Prec@1 88.806
Test: [0/50]	Time 0.103 (0.103)	Loss 0.5387 (0.5387)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.090
Epoch: [39/80][0/250]	LR: 0.1	Time 0.116 (0.116)	Data 0.093 (0.093)	Loss 0.2002 (0.2002)	Prec@1 93.000 (93.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.032 (0.038)	Data 0.018 (0.025)	Loss 0.2899 (0.3195)	Prec@1 89.000 (89.005)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.031 (0.035)	Data 0.018 (0.022)	Loss 0.2480 (0.3164)	Prec@1 91.500 (89.157)
 * Training Prec@1 89.080
Test: [0/50]	Time 0.108 (0.108)	Loss 0.5284 (0.5284)	Prec@1 82.500 (82.500)
 * Testing Prec@1 84.450
Epoch: [40/80][0/250]	LR: 0.01	Time 0.112 (0.112)	Data 0.093 (0.093)	Loss 0.2662 (0.2662)	Prec@1 93.000 (93.000)
Epoch: [40/80][100/250]	LR: 0.01	Time 0.030 (0.034)	Data 0.018 (0.020)	Loss 0.2582 (0.2371)	Prec@1 91.500 (92.035)
Epoch: [40/80][200/250]	LR: 0.01	Time 0.032 (0.033)	Data 0.019 (0.020)	Loss 0.2278 (0.2270)	Prec@1 90.500 (92.306)
 * Training Prec@1 92.360
Test: [0/50]	Time 0.106 (0.106)	Loss 0.3038 (0.3038)	Prec@1 89.500 (89.500)
 * Testing Prec@1 88.490
Epoch: [41/80][0/250]	LR: 0.01	Time 0.171 (0.171)	Data 0.146 (0.146)	Loss 0.1659 (0.1659)	Prec@1 92.500 (92.500)
Epoch: [41/80][100/250]	LR: 0.01	Time 0.032 (0.036)	Data 0.018 (0.021)	Loss 0.2035 (0.1980)	Prec@1 93.500 (93.282)
Epoch: [41/80][200/250]	LR: 0.01	Time 0.032 (0.034)	Data 0.018 (0.019)	Loss 0.1724 (0.1968)	Prec@1 94.000 (93.286)
 * Training Prec@1 93.288
Test: [0/50]	Time 0.107 (0.107)	Loss 0.3018 (0.3018)	Prec@1 89.500 (89.500)
 * Testing Prec@1 88.920
Epoch: [42/80][0/250]	LR: 0.01	Time 0.145 (0.145)	Data 0.126 (0.126)	Loss 0.2507 (0.2507)	Prec@1 92.500 (92.500)
Epoch: [42/80][100/250]	LR: 0.01	Time 0.031 (0.038)	Data 0.018 (0.023)	Loss 0.2266 (0.1920)	Prec@1 92.500 (93.401)
Epoch: [42/80][200/250]	LR: 0.01	Time 0.042 (0.036)	Data 0.026 (0.021)	Loss 0.1281 (0.1871)	Prec@1 94.500 (93.547)
 * Training Prec@1 93.522
Test: [0/50]	Time 0.111 (0.111)	Loss 0.3029 (0.3029)	Prec@1 88.500 (88.500)
 * Testing Prec@1 89.170
Epoch: [43/80][0/250]	LR: 0.01	Time 0.151 (0.151)	Data 0.129 (0.129)	Loss 0.1642 (0.1642)	Prec@1 93.000 (93.000)
Epoch: [43/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.019 (0.021)	Loss 0.1572 (0.1777)	Prec@1 95.000 (93.931)
Epoch: [43/80][200/250]	LR: 0.01	Time 0.033 (0.034)	Data 0.019 (0.020)	Loss 0.1628 (0.1760)	Prec@1 94.500 (93.998)
 * Training Prec@1 93.932
Test: [0/50]	Time 0.103 (0.103)	Loss 0.2982 (0.2982)	Prec@1 89.000 (89.000)
 * Testing Prec@1 89.080
Epoch: [44/80][0/250]	LR: 0.01	Time 0.117 (0.117)	Data 0.094 (0.094)	Loss 0.1395 (0.1395)	Prec@1 97.000 (97.000)
Epoch: [44/80][100/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.019 (0.020)	Loss 0.1827 (0.1701)	Prec@1 93.000 (94.322)
Epoch: [44/80][200/250]	LR: 0.01	Time 0.032 (0.034)	Data 0.019 (0.020)	Loss 0.1429 (0.1713)	Prec@1 95.500 (94.179)
 * Training Prec@1 94.132
Test: [0/50]	Time 0.102 (0.102)	Loss 0.3050 (0.3050)	Prec@1 88.500 (88.500)
 * Testing Prec@1 88.960
Epoch: [45/80][0/250]	LR: 0.01	Time 0.180 (0.180)	Data 0.161 (0.161)	Loss 0.1949 (0.1949)	Prec@1 93.500 (93.500)
Epoch: [45/80][100/250]	LR: 0.01	Time 0.031 (0.034)	Data 0.017 (0.020)	Loss 0.1641 (0.1695)	Prec@1 94.500 (94.233)
Epoch: [45/80][200/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.019 (0.021)	Loss 0.1479 (0.1677)	Prec@1 93.500 (94.276)
 * Training Prec@1 94.216
Test: [0/50]	Time 0.108 (0.108)	Loss 0.3054 (0.3054)	Prec@1 88.500 (88.500)
 * Testing Prec@1 88.900
Epoch: [46/80][0/250]	LR: 0.01	Time 0.148 (0.148)	Data 0.126 (0.126)	Loss 0.2072 (0.2072)	Prec@1 93.500 (93.500)
Epoch: [46/80][100/250]	LR: 0.01	Time 0.033 (0.037)	Data 0.020 (0.022)	Loss 0.1640 (0.1631)	Prec@1 94.500 (94.307)
Epoch: [46/80][200/250]	LR: 0.01	Time 0.034 (0.036)	Data 0.019 (0.022)	Loss 0.1428 (0.1632)	Prec@1 95.000 (94.316)
 * Training Prec@1 94.198
Test: [0/50]	Time 0.103 (0.103)	Loss 0.2989 (0.2989)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.250
Epoch: [47/80][0/250]	LR: 0.01	Time 0.160 (0.160)	Data 0.136 (0.136)	Loss 0.1280 (0.1280)	Prec@1 95.000 (95.000)
Epoch: [47/80][100/250]	LR: 0.01	Time 0.045 (0.038)	Data 0.028 (0.023)	Loss 0.2224 (0.1625)	Prec@1 89.500 (94.436)
Epoch: [47/80][200/250]	LR: 0.01	Time 0.035 (0.036)	Data 0.021 (0.021)	Loss 0.1214 (0.1619)	Prec@1 96.500 (94.363)
 * Training Prec@1 94.394
Test: [0/50]	Time 0.112 (0.112)	Loss 0.3295 (0.3295)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.060
Epoch: [48/80][0/250]	LR: 0.01	Time 0.179 (0.179)	Data 0.155 (0.155)	Loss 0.1729 (0.1729)	Prec@1 93.000 (93.000)
Epoch: [48/80][100/250]	LR: 0.01	Time 0.032 (0.034)	Data 0.018 (0.020)	Loss 0.1122 (0.1508)	Prec@1 96.000 (94.564)
Epoch: [48/80][200/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.1109 (0.1584)	Prec@1 97.500 (94.450)
 * Training Prec@1 94.454
Test: [0/50]	Time 0.106 (0.106)	Loss 0.2950 (0.2950)	Prec@1 89.000 (89.000)
 * Testing Prec@1 89.090
Epoch: [49/80][0/250]	LR: 0.01	Time 0.161 (0.161)	Data 0.137 (0.137)	Loss 0.1620 (0.1620)	Prec@1 94.500 (94.500)
Epoch: [49/80][100/250]	LR: 0.01	Time 0.034 (0.036)	Data 0.020 (0.020)	Loss 0.1115 (0.1541)	Prec@1 97.000 (94.579)
Epoch: [49/80][200/250]	LR: 0.01	Time 0.035 (0.035)	Data 0.021 (0.020)	Loss 0.1849 (0.1559)	Prec@1 93.000 (94.490)
 * Training Prec@1 94.448
Test: [0/50]	Time 0.096 (0.096)	Loss 0.2941 (0.2941)	Prec@1 89.000 (89.000)
 * Testing Prec@1 89.090
Epoch: [50/80][0/250]	LR: 0.01	Time 0.155 (0.155)	Data 0.132 (0.132)	Loss 0.1866 (0.1866)	Prec@1 94.500 (94.500)
Epoch: [50/80][100/250]	LR: 0.01	Time 0.032 (0.036)	Data 0.018 (0.022)	Loss 0.1122 (0.1543)	Prec@1 97.500 (94.594)
Epoch: [50/80][200/250]	LR: 0.01	Time 0.032 (0.035)	Data 0.019 (0.020)	Loss 0.1604 (0.1518)	Prec@1 94.500 (94.677)
 * Training Prec@1 94.740
Test: [0/50]	Time 0.097 (0.097)	Loss 0.3171 (0.3171)	Prec@1 86.500 (86.500)
 * Testing Prec@1 89.090
Epoch: [51/80][0/250]	LR: 0.01	Time 0.184 (0.184)	Data 0.160 (0.160)	Loss 0.1214 (0.1214)	Prec@1 96.500 (96.500)
Epoch: [51/80][100/250]	LR: 0.01	Time 0.039 (0.036)	Data 0.022 (0.021)	Loss 0.1448 (0.1486)	Prec@1 96.000 (94.817)
Epoch: [51/80][200/250]	LR: 0.01	Time 0.034 (0.036)	Data 0.020 (0.021)	Loss 0.1548 (0.1510)	Prec@1 95.500 (94.721)
 * Training Prec@1 94.682
Test: [0/50]	Time 0.104 (0.104)	Loss 0.2999 (0.2999)	Prec@1 88.500 (88.500)
 * Testing Prec@1 89.260
Epoch: [52/80][0/250]	LR: 0.01	Time 0.153 (0.153)	Data 0.130 (0.130)	Loss 0.1480 (0.1480)	Prec@1 95.500 (95.500)
Epoch: [52/80][100/250]	LR: 0.01	Time 0.035 (0.039)	Data 0.022 (0.024)	Loss 0.1038 (0.1480)	Prec@1 96.000 (95.005)
Epoch: [52/80][200/250]	LR: 0.01	Time 0.033 (0.037)	Data 0.016 (0.022)	Loss 0.1809 (0.1471)	Prec@1 95.000 (94.965)
 * Training Prec@1 94.934
Test: [0/50]	Time 0.096 (0.096)	Loss 0.3078 (0.3078)	Prec@1 87.000 (87.000)
 * Testing Prec@1 88.840
Epoch: [53/80][0/250]	LR: 0.01	Time 0.181 (0.181)	Data 0.158 (0.158)	Loss 0.1155 (0.1155)	Prec@1 96.000 (96.000)
Epoch: [53/80][100/250]	LR: 0.01	Time 0.032 (0.036)	Data 0.019 (0.021)	Loss 0.2139 (0.1477)	Prec@1 92.000 (94.827)
Epoch: [53/80][200/250]	LR: 0.01	Time 0.033 (0.034)	Data 0.019 (0.020)	Loss 0.0954 (0.1467)	Prec@1 97.000 (94.888)
 * Training Prec@1 94.896
Test: [0/50]	Time 0.102 (0.102)	Loss 0.3194 (0.3194)	Prec@1 89.000 (89.000)
 * Testing Prec@1 89.130
Epoch: [54/80][0/250]	LR: 0.01	Time 0.167 (0.167)	Data 0.144 (0.144)	Loss 0.1424 (0.1424)	Prec@1 94.500 (94.500)
Epoch: [54/80][100/250]	LR: 0.01	Time 0.033 (0.036)	Data 0.020 (0.022)	Loss 0.1499 (0.1422)	Prec@1 95.000 (95.005)
Epoch: [54/80][200/250]	LR: 0.01	Time 0.031 (0.034)	Data 0.018 (0.020)	Loss 0.2065 (0.1418)	Prec@1 92.500 (95.107)
 * Training Prec@1 95.044
Test: [0/50]	Time 0.093 (0.093)	Loss 0.3135 (0.3135)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.130
Epoch: [55/80][0/250]	LR: 0.01	Time 0.114 (0.114)	Data 0.093 (0.093)	Loss 0.1516 (0.1516)	Prec@1 96.000 (96.000)
Epoch: [55/80][100/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.019 (0.021)	Loss 0.1799 (0.1350)	Prec@1 92.500 (95.411)
Epoch: [55/80][200/250]	LR: 0.01	Time 0.034 (0.035)	Data 0.019 (0.020)	Loss 0.1056 (0.1362)	Prec@1 96.500 (95.313)
 * Training Prec@1 95.248
Test: [0/50]	Time 0.104 (0.104)	Loss 0.3093 (0.3093)	Prec@1 87.000 (87.000)
 * Testing Prec@1 88.870
Epoch: [56/80][0/250]	LR: 0.01	Time 0.141 (0.141)	Data 0.123 (0.123)	Loss 0.1654 (0.1654)	Prec@1 94.500 (94.500)
Epoch: [56/80][100/250]	LR: 0.01	Time 0.031 (0.035)	Data 0.018 (0.020)	Loss 0.0911 (0.1355)	Prec@1 97.500 (95.361)
Epoch: [56/80][200/250]	LR: 0.01	Time 0.034 (0.034)	Data 0.020 (0.019)	Loss 0.1479 (0.1350)	Prec@1 94.000 (95.373)
 * Training Prec@1 95.286
Test: [0/50]	Time 0.109 (0.109)	Loss 0.3210 (0.3210)	Prec@1 88.500 (88.500)
 * Testing Prec@1 89.030
Epoch: [57/80][0/250]	LR: 0.01	Time 0.192 (0.192)	Data 0.167 (0.167)	Loss 0.1192 (0.1192)	Prec@1 95.000 (95.000)
Epoch: [57/80][100/250]	LR: 0.01	Time 0.035 (0.041)	Data 0.023 (0.025)	Loss 0.1215 (0.1318)	Prec@1 95.000 (95.530)
Epoch: [57/80][200/250]	LR: 0.01	Time 0.032 (0.038)	Data 0.018 (0.022)	Loss 0.2093 (0.1363)	Prec@1 94.000 (95.328)
 * Training Prec@1 95.284
Test: [0/50]	Time 0.103 (0.103)	Loss 0.3016 (0.3016)	Prec@1 89.000 (89.000)
 * Testing Prec@1 88.870
Epoch: [58/80][0/250]	LR: 0.01	Time 0.172 (0.172)	Data 0.149 (0.149)	Loss 0.0970 (0.0970)	Prec@1 97.500 (97.500)
Epoch: [58/80][100/250]	LR: 0.01	Time 0.030 (0.037)	Data 0.016 (0.023)	Loss 0.1788 (0.1359)	Prec@1 94.000 (95.198)
Epoch: [58/80][200/250]	LR: 0.01	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.1392 (0.1337)	Prec@1 95.500 (95.271)
 * Training Prec@1 95.238
Test: [0/50]	Time 0.076 (0.076)	Loss 0.3038 (0.3038)	Prec@1 89.000 (89.000)
 * Testing Prec@1 89.080
Epoch: [59/80][0/250]	LR: 0.01	Time 0.141 (0.141)	Data 0.119 (0.119)	Loss 0.1958 (0.1958)	Prec@1 92.500 (92.500)
Epoch: [59/80][100/250]	LR: 0.01	Time 0.032 (0.039)	Data 0.020 (0.023)	Loss 0.0919 (0.1278)	Prec@1 97.500 (95.515)
Epoch: [59/80][200/250]	LR: 0.01	Time 0.044 (0.037)	Data 0.027 (0.022)	Loss 0.1001 (0.1294)	Prec@1 97.500 (95.537)
 * Training Prec@1 95.430
Test: [0/50]	Time 0.111 (0.111)	Loss 0.3091 (0.3091)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.100
Epoch: [60/80][0/250]	LR: 0.001	Time 0.184 (0.184)	Data 0.161 (0.161)	Loss 0.1065 (0.1065)	Prec@1 96.000 (96.000)
Epoch: [60/80][100/250]	LR: 0.001	Time 0.041 (0.035)	Data 0.026 (0.021)	Loss 0.1121 (0.1229)	Prec@1 96.500 (95.693)
Epoch: [60/80][200/250]	LR: 0.001	Time 0.034 (0.036)	Data 0.020 (0.022)	Loss 0.1150 (0.1220)	Prec@1 96.500 (95.811)
 * Training Prec@1 95.774
Test: [0/50]	Time 0.102 (0.102)	Loss 0.3309 (0.3309)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.280
Epoch: [61/80][0/250]	LR: 0.001	Time 0.151 (0.151)	Data 0.128 (0.128)	Loss 0.1260 (0.1260)	Prec@1 95.500 (95.500)
Epoch: [61/80][100/250]	LR: 0.001	Time 0.031 (0.035)	Data 0.017 (0.021)	Loss 0.0807 (0.1210)	Prec@1 97.500 (95.807)
Epoch: [61/80][200/250]	LR: 0.001	Time 0.033 (0.034)	Data 0.021 (0.021)	Loss 0.0987 (0.1202)	Prec@1 97.000 (95.955)
 * Training Prec@1 95.976
Test: [0/50]	Time 0.104 (0.104)	Loss 0.3147 (0.3147)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.210
Epoch: [62/80][0/250]	LR: 0.001	Time 0.163 (0.163)	Data 0.138 (0.138)	Loss 0.1097 (0.1097)	Prec@1 96.500 (96.500)
Epoch: [62/80][100/250]	LR: 0.001	Time 0.033 (0.037)	Data 0.019 (0.021)	Loss 0.1500 (0.1158)	Prec@1 93.500 (95.936)
Epoch: [62/80][200/250]	LR: 0.001	Time 0.034 (0.035)	Data 0.020 (0.020)	Loss 0.1102 (0.1174)	Prec@1 96.500 (95.918)
 * Training Prec@1 95.878
Test: [0/50]	Time 0.109 (0.109)	Loss 0.3161 (0.3161)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.310
Epoch: [63/80][0/250]	LR: 0.001	Time 0.170 (0.170)	Data 0.145 (0.145)	Loss 0.1268 (0.1268)	Prec@1 96.500 (96.500)
Epoch: [63/80][100/250]	LR: 0.001	Time 0.041 (0.037)	Data 0.026 (0.021)	Loss 0.1427 (0.1112)	Prec@1 94.500 (96.371)
Epoch: [63/80][200/250]	LR: 0.001	Time 0.041 (0.037)	Data 0.027 (0.021)	Loss 0.0813 (0.1150)	Prec@1 97.500 (96.109)
 * Training Prec@1 96.022
Test: [0/50]	Time 0.111 (0.111)	Loss 0.3169 (0.3169)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.350
Epoch: [64/80][0/250]	LR: 0.001	Time 0.135 (0.135)	Data 0.112 (0.112)	Loss 0.0873 (0.0873)	Prec@1 97.000 (97.000)
Epoch: [64/80][100/250]	LR: 0.001	Time 0.032 (0.033)	Data 0.018 (0.018)	Loss 0.0897 (0.1159)	Prec@1 97.000 (96.173)
Epoch: [64/80][200/250]	LR: 0.001	Time 0.033 (0.033)	Data 0.018 (0.018)	Loss 0.1321 (0.1164)	Prec@1 95.000 (96.107)
 * Training Prec@1 96.072
Test: [0/50]	Time 0.100 (0.100)	Loss 0.3269 (0.3269)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.290
Epoch: [65/80][0/250]	LR: 0.001	Time 0.187 (0.187)	Data 0.164 (0.164)	Loss 0.1198 (0.1198)	Prec@1 95.500 (95.500)
Epoch: [65/80][100/250]	LR: 0.001	Time 0.032 (0.038)	Data 0.020 (0.023)	Loss 0.1219 (0.1112)	Prec@1 94.500 (96.208)
Epoch: [65/80][200/250]	LR: 0.001	Time 0.031 (0.035)	Data 0.018 (0.021)	Loss 0.1490 (0.1132)	Prec@1 94.500 (96.187)
 * Training Prec@1 96.114
Test: [0/50]	Time 0.099 (0.099)	Loss 0.3177 (0.3177)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.260
Epoch: [66/80][0/250]	LR: 0.001	Time 0.097 (0.097)	Data 0.078 (0.078)	Loss 0.0942 (0.0942)	Prec@1 96.500 (96.500)
Epoch: [66/80][100/250]	LR: 0.001	Time 0.043 (0.033)	Data 0.026 (0.020)	Loss 0.1036 (0.1143)	Prec@1 97.500 (96.114)
Epoch: [66/80][200/250]	LR: 0.001	Time 0.033 (0.033)	Data 0.020 (0.020)	Loss 0.1207 (0.1138)	Prec@1 96.000 (96.077)
 * Training Prec@1 96.158
Test: [0/50]	Time 0.107 (0.107)	Loss 0.3253 (0.3253)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.330
Epoch: [67/80][0/250]	LR: 0.001	Time 0.160 (0.160)	Data 0.136 (0.136)	Loss 0.1108 (0.1108)	Prec@1 95.500 (95.500)
Epoch: [67/80][100/250]	LR: 0.001	Time 0.033 (0.036)	Data 0.020 (0.022)	Loss 0.1555 (0.1140)	Prec@1 94.500 (95.985)
Epoch: [67/80][200/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.020 (0.021)	Loss 0.1287 (0.1131)	Prec@1 96.000 (96.015)
 * Training Prec@1 95.974
Test: [0/50]	Time 0.070 (0.070)	Loss 0.3221 (0.3221)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.240
Epoch: [68/80][0/250]	LR: 0.001	Time 0.163 (0.163)	Data 0.138 (0.138)	Loss 0.1267 (0.1267)	Prec@1 94.000 (94.000)
Epoch: [68/80][100/250]	LR: 0.001	Time 0.031 (0.035)	Data 0.016 (0.021)	Loss 0.1014 (0.1144)	Prec@1 96.000 (96.064)
Epoch: [68/80][200/250]	LR: 0.001	Time 0.031 (0.034)	Data 0.019 (0.020)	Loss 0.0897 (0.1148)	Prec@1 96.500 (95.995)
 * Training Prec@1 96.034
Test: [0/50]	Time 0.100 (0.100)	Loss 0.3201 (0.3201)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.460
Epoch: [69/80][0/250]	LR: 0.001	Time 0.122 (0.122)	Data 0.100 (0.100)	Loss 0.0904 (0.0904)	Prec@1 97.500 (97.500)
Epoch: [69/80][100/250]	LR: 0.001	Time 0.046 (0.036)	Data 0.029 (0.022)	Loss 0.1644 (0.1146)	Prec@1 96.500 (96.099)
Epoch: [69/80][200/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.019 (0.020)	Loss 0.1057 (0.1156)	Prec@1 97.000 (96.010)
 * Training Prec@1 96.020
Test: [0/50]	Time 0.103 (0.103)	Loss 0.3038 (0.3038)	Prec@1 87.500 (87.500)
 * Testing Prec@1 89.350
Epoch: [70/80][0/250]	LR: 0.001	Time 0.177 (0.177)	Data 0.154 (0.154)	Loss 0.1188 (0.1188)	Prec@1 95.500 (95.500)
Epoch: [70/80][100/250]	LR: 0.001	Time 0.032 (0.036)	Data 0.019 (0.021)	Loss 0.1153 (0.1121)	Prec@1 97.000 (96.144)
Epoch: [70/80][200/250]	LR: 0.001	Time 0.034 (0.034)	Data 0.020 (0.020)	Loss 0.1533 (0.1153)	Prec@1 94.500 (96.072)
 * Training Prec@1 96.036
Test: [0/50]	Time 0.070 (0.070)	Loss 0.3069 (0.3069)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.420
Epoch: [71/80][0/250]	LR: 0.001	Time 0.149 (0.149)	Data 0.127 (0.127)	Loss 0.0793 (0.0793)	Prec@1 97.500 (97.500)
Epoch: [71/80][100/250]	LR: 0.001	Time 0.031 (0.033)	Data 0.018 (0.019)	Loss 0.1359 (0.1140)	Prec@1 96.000 (96.139)
Epoch: [71/80][200/250]	LR: 0.001	Time 0.032 (0.033)	Data 0.019 (0.019)	Loss 0.0979 (0.1115)	Prec@1 96.000 (96.229)
 * Training Prec@1 96.170
Test: [0/50]	Time 0.065 (0.065)	Loss 0.3172 (0.3172)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.390
Epoch: [72/80][0/250]	LR: 0.001	Time 0.149 (0.149)	Data 0.126 (0.126)	Loss 0.0948 (0.0948)	Prec@1 97.000 (97.000)
Epoch: [72/80][100/250]	LR: 0.001	Time 0.042 (0.038)	Data 0.024 (0.022)	Loss 0.0822 (0.1109)	Prec@1 96.500 (96.183)
Epoch: [72/80][200/250]	LR: 0.001	Time 0.032 (0.038)	Data 0.018 (0.022)	Loss 0.1232 (0.1095)	Prec@1 95.500 (96.234)
 * Training Prec@1 96.134
Test: [0/50]	Time 0.105 (0.105)	Loss 0.3129 (0.3129)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.270
Epoch: [73/80][0/250]	LR: 0.001	Time 0.164 (0.164)	Data 0.140 (0.140)	Loss 0.1242 (0.1242)	Prec@1 94.500 (94.500)
Epoch: [73/80][100/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.019 (0.021)	Loss 0.0943 (0.1085)	Prec@1 97.500 (96.347)
Epoch: [73/80][200/250]	LR: 0.001	Time 0.031 (0.034)	Data 0.018 (0.020)	Loss 0.0661 (0.1129)	Prec@1 98.000 (96.102)
 * Training Prec@1 96.108
Test: [0/50]	Time 0.102 (0.102)	Loss 0.3159 (0.3159)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.230
Epoch: [74/80][0/250]	LR: 0.001	Time 0.122 (0.122)	Data 0.100 (0.100)	Loss 0.0804 (0.0804)	Prec@1 97.500 (97.500)
Epoch: [74/80][100/250]	LR: 0.001	Time 0.036 (0.035)	Data 0.023 (0.021)	Loss 0.0770 (0.1105)	Prec@1 96.500 (96.287)
Epoch: [74/80][200/250]	LR: 0.001	Time 0.034 (0.036)	Data 0.020 (0.022)	Loss 0.0811 (0.1099)	Prec@1 97.000 (96.363)
 * Training Prec@1 96.314
Test: [0/50]	Time 0.139 (0.139)	Loss 0.3206 (0.3206)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.360
Epoch: [75/80][0/250]	LR: 0.001	Time 0.130 (0.130)	Data 0.108 (0.108)	Loss 0.1252 (0.1252)	Prec@1 96.000 (96.000)
Epoch: [75/80][100/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.018 (0.021)	Loss 0.1468 (0.1105)	Prec@1 95.000 (96.168)
Epoch: [75/80][200/250]	LR: 0.001	Time 0.034 (0.035)	Data 0.019 (0.020)	Loss 0.1970 (0.1117)	Prec@1 93.500 (96.187)
 * Training Prec@1 96.270
Test: [0/50]	Time 0.090 (0.090)	Loss 0.3202 (0.3202)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.380
Epoch: [76/80][0/250]	LR: 0.001	Time 0.126 (0.126)	Data 0.104 (0.104)	Loss 0.1130 (0.1130)	Prec@1 96.000 (96.000)
Epoch: [76/80][100/250]	LR: 0.001	Time 0.037 (0.039)	Data 0.020 (0.024)	Loss 0.1756 (0.1142)	Prec@1 94.000 (96.188)
Epoch: [76/80][200/250]	LR: 0.001	Time 0.034 (0.037)	Data 0.021 (0.022)	Loss 0.0885 (0.1126)	Prec@1 97.500 (96.201)
 * Training Prec@1 96.166
Test: [0/50]	Time 0.099 (0.099)	Loss 0.3166 (0.3166)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.180
Epoch: [77/80][0/250]	LR: 0.001	Time 0.176 (0.176)	Data 0.154 (0.154)	Loss 0.0942 (0.0942)	Prec@1 96.500 (96.500)
Epoch: [77/80][100/250]	LR: 0.001	Time 0.035 (0.038)	Data 0.019 (0.022)	Loss 0.1337 (0.1143)	Prec@1 96.500 (95.886)
Epoch: [77/80][200/250]	LR: 0.001	Time 0.033 (0.035)	Data 0.018 (0.021)	Loss 0.0982 (0.1109)	Prec@1 97.000 (96.114)
 * Training Prec@1 96.112
Test: [0/50]	Time 0.104 (0.104)	Loss 0.3272 (0.3272)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.320
Epoch: [78/80][0/250]	LR: 0.001	Time 0.150 (0.150)	Data 0.129 (0.129)	Loss 0.1628 (0.1628)	Prec@1 94.000 (94.000)
Epoch: [78/80][100/250]	LR: 0.001	Time 0.034 (0.038)	Data 0.020 (0.023)	Loss 0.1009 (0.1058)	Prec@1 97.000 (96.391)
Epoch: [78/80][200/250]	LR: 0.001	Time 0.044 (0.037)	Data 0.027 (0.022)	Loss 0.1727 (0.1075)	Prec@1 92.500 (96.306)
 * Training Prec@1 96.268
Test: [0/50]	Time 0.103 (0.103)	Loss 0.3256 (0.3256)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.410
Epoch: [79/80][0/250]	LR: 0.001	Time 0.112 (0.112)	Data 0.092 (0.092)	Loss 0.1517 (0.1517)	Prec@1 93.000 (93.000)
Epoch: [79/80][100/250]	LR: 0.001	Time 0.032 (0.035)	Data 0.019 (0.021)	Loss 0.1395 (0.1099)	Prec@1 94.000 (96.238)
Epoch: [79/80][200/250]	LR: 0.001	Time 0.032 (0.033)	Data 0.019 (0.020)	Loss 0.0648 (0.1100)	Prec@1 98.000 (96.177)
 * Training Prec@1 96.176
Test: [0/50]	Time 0.089 (0.089)	Loss 0.3305 (0.3305)	Prec@1 88.000 (88.000)
 * Testing Prec@1 89.300
